# -*- coding: utf-8 -*-
"""Copy of deep_learning_for_computer_vision_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P8C4Lerr6uPv1hS_6T0JGlpo7xFNxLOO

seg.nii.gz: Segmentation mask

t1c.nii.gz: T1-weighted contrast-enhanced image

t1n.nii.gz: Native T1-weighted image

t2f.nii.gz: Fluid-attenuated inversion recovery (FLAIR) T2-weighted image

t2w.nii.gz: T2-weighted image

 Nibabel (for reading .nii.gz files)
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install -q kaggle
# %cd /content
!pwd

from google.colab import files
files.upload()
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets list

from google.colab import drive

drive.mount('/content/drive')
model_path = "/content/drive/My Drive/DL for CV/"

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
# %cd /content

!kaggle datasets download -d awsaf49/brats2020-training-data

! unzip brats2020-training-data.zip

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
import pandas as pd
df = pd.read_csv("BraTS2020_training_data/content/data/survival_info.csv")
df

# Commented out IPython magic to ensure Python compatibility.
# %pwd

import numpy as np
import os
import h5py
import random
directory = "BraTS2020_training_data/content/data"

h5_files = [f for f in os.listdir(directory) if f.endswith('.h5')]
print(f"Found {len(h5_files)} .h5 files")
if h5_files:
    selected_file = random.choice(h5_files)
    file_path = os.path.join(directory, selected_file)
    with h5py.File(file_path, 'r') as file:
        print("\nKeys for each file:", list(file.keys()))
        for key in file.keys():
            print(f"\nData type of {key}:", type(file[key][()]))
            print(f"Shape of {key}:", file[key].shape)
            print(f"Array dtype: {file[key].dtype}")
            print(f"Array max val: {np.max(file[key])}")
            print(f"Array min val: {np.min(file[key])}")
else:
    print("No .h5 files found in the directory.")

import matplotlib.pyplot as plt

with h5py.File('BraTS2020_training_data/content/data/volume_100_slice_50.h5', 'r') as file:
  image = file['image'][:]
  mask = file['mask'][:]

plt.figure(figsize = (10,10))

for i in range(4):
  plt.subplot(2, 4, i + 1)
  plt.imshow(image[:, :, i], cmap='gray')
  plt.title(f'Channel {i + 1}')
  plt.axis('off')

for i in range(3):
    plt.subplot(2, 4, i + 5)
    plt.imshow(mask[:, :, i], cmap='gray')
    plt.title(f'Mask Channel {i + 1}')
    plt.axis('off')

!pip install SimpleITK
import SimpleITK as sitk

def load_image(h5_file_path, channel):
    with h5py.File(h5_file_path, 'r') as file:
        image_data = file['image'][:]
    if len(image_data.shape) > 2:
        image_data = image_data[:, :, channel]
    return image_data

def n4bias_and_normalize(h5_file_path, channel):
    original_image = load_image(h5_file_path, channel)
    sitk_image = sitk.GetImageFromArray(original_image)
    corrector = sitk.N4BiasFieldCorrectionImageFilter()
    corrected_image = corrector.Execute(sitk_image)
    corrected_array = sitk.GetArrayFromImage(corrected_image)
    mean = np.mean(corrected_array)
    print(mean)
    std = np.std(corrected_array)
    print(std)
    normalized_array = (corrected_array - mean) / std

    mean = np.mean(normalized_array)
    print(mean)
    std = np.std(normalized_array)
    print(std)
    return original_image, corrected_array, normalized_array



h5_file_path = 'BraTS2020_training_data/content/data/volume_30_slice_50.h5'
channel = 0
i = 1
for channel in range(4):
  original, corrected, normalized = n4bias_and_normalize(h5_file_path, channel)
  plt.figure(figsize=(9, 12))

  plt.subplot(4, 3, i)
  plt.imshow(original, cmap='gray')
  plt.title('Original Image')
  plt.axis('off')
  i+=1

  plt.subplot(4, 3, i)
  plt.imshow(corrected, cmap='gray')
  plt.title('Corrected Image')
  plt.axis('off')
  i+=1

  plt.subplot(4, 3, i)
  plt.imshow(normalized, cmap='gray')
  plt.title('Normalized Image')
  plt.axis('off')
  i+=1

plt.tight_layout()
plt.show()

import torch
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split
import numpy as np
from torchvision import transforms
import os

!pip install SimpleITK
import h5py
import SimpleITK as sitk



def one_hot_mask(mask):
    class_mask = np.zeros((240, 240, 4), dtype=np.uint8)

    for class_idx in range(3):
        class_mask[mask[:, :, class_idx] > 0, class_idx + 1] = 1
    class_mask[mask.sum(axis=-1) == 0, 0] = 1

    return class_mask

class SegmentationDataset(Dataset):
    def __init__(self, image_path, transform=None):
        self.image_path = image_path
        self.images = [f for f in os.listdir(image_path) if f.endswith('.h5')]

        print(len(self.images))
        self.transform = transform

    def __len__(self):
      return len(self.images)
    def __getitem__(self, idx):
      try:
        with h5py.File(os.path.join(self.image_path, self.images[idx]), 'r') as file:
          image = np.array(file['image'])
          mask = np.array(file['mask'])
          image = torch.tensor(image, dtype=torch.float).permute(2, 0, 1)
          mask = one_hot_mask(mask)
          mask = torch.tensor(mask, dtype=torch.long).permute(2, 0, 1)
          image = self.transform(image)
          mask = self.transform(mask)
          return image, mask
      except Exception as e:
        # Catch and log any error
        print(f"Error processing file {self.images[idx]}: {e}")

def make_dataloaders(image_path, batch_size, transform):
  dataset = SegmentationDataset(image_path, transform = transform)
  train_size = int(0.8 * len(dataset))
  val_size = int(0.1 * len(dataset))
  test_size = len(dataset) - train_size - val_size

  generator1 = torch.Generator().manual_seed(42)
  train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator = generator1)
  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

  return train_loader, val_loader, test_loader


class DiceLoss(nn.Module):
    def __init__(self, class_weights=None):
        super(DiceLoss, self).__init__()
        self.class_weights = class_weights

    def forward(self, predicted_mask, true_mask, smooth_coef=1.0):
        predicted_mask = torch.nn.functional.softmax(predicted_mask, dim=1) #torch.Size([batch, 4, 256, 256])
        true_mask = true_mask.float() #torch.Size([batch, 4, 256, 256])

        predicted_mask = predicted_mask.view(predicted_mask.size(0), predicted_mask.size(1), -1) #torch.Size([batch, 4, 65536])
        true_mask = true_mask.view(true_mask.size(0), true_mask.size(1), -1) #torch.Size([batch, 4, 65536])

        intersection = (predicted_mask * true_mask).sum(dim=2) #torch.Size([batch, 4])
        total = predicted_mask.sum(dim=2) + true_mask.sum(dim=2) #torch.Size([batch, 4])

        if self.class_weights is not None:
            self.class_weights = self.class_weights.to(predicted_mask.device)
            intersection = intersection * self.class_weights
            total = total * self.class_weights


        dice_score = (2 * intersection + smooth_coef) / (total + smooth_coef) #torch.Size([batch, 4])

        return 1 - dice_score.mean() #torch.Size([])

import time
import tqdm
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image
from google.colab import drive
from torch.optim.lr_scheduler import StepLR
from google.colab import files
from google.colab import drive
drive.mount('/content/drive')
model_path = "/content/drive/My Drive/DL for CV/"


def train_model(model, optimizer, scheduler, loss_function, num_epochs, train_loader, val_loader, patience, name):
  lowest_val_loss = 100000000
  patience_counter = patience
  for epoch in range(num_epochs):
    start_time = time.time()
    model.train()
    train_loss = 0
    for x, y in tqdm(train_loader, desc=f"Epoch:{epoch + 1}", leave=False):  # progress bar
      x, y = x.to(device), y.to(device)
      optimizer.zero_grad()
      predicted_y = model(x)

      y = y.float()

      loss = loss_function(predicted_y, y)
      loss.backward()  # Backpropagate gradients

      optimizer.step()
      train_loss += loss.item()
    train_loss /= len(train_loader)
    model.eval()
    val_loss = 0 #checking validation loss
    for x, y in val_loader:
      x, y = x.to(device), y.to(device)
      with torch.no_grad():
        predicted_y = model(x)
        loss = loss_function(predicted_y.squeeze(), y.float())
        val_loss += loss.item()
    val_loss /= len(val_loader)

    if (val_loss<lowest_val_loss): #if our validation loss is less than the lowest one so far, save the model out
      torch.save(model.state_dict(), f"{model_path}{name}.py")
      patience_counter = patience
      lowest_val_loss = val_loss #update the lowest loss

    elif (val_loss >= lowest_val_loss):#reduce patience
      patience_counter-= 1
      if patience_counter == 0:
          print(f"Ran out of patience. Best Model Val Loss: {lowest_val_loss}")
          break;
    end_time = time.time()
    epoch_duration = end_time - start_time #timing our epoch
    print(f'Epoch{epoch+1} of num_epochs; Train Loss: {train_loss}; Val Loss: {val_loss}; Patience: {patience_counter}; Time: {epoch_duration}')
    scheduler.step()

  model.load_state_dict(torch.load(f"{model_path}{name}.py")) #load our best model
  return model


#tests the given model and outputs images if print_sample_mistakes is True
def test_model(model, test_loader, name, print_sample_mistakes = True):
  model.load_state_dict(torch.load(f"{model_path}{name}.py"))
  model.eval()
  dice= 0
  for x, y in test_loader:
    with torch.no_grad():
      print(x)
      print(x.shape)
      print(y)
      print(y.shape)
      x, y = x.to(device), y.to(device)
      predicted_y = model(x)
      print(predicted_y)
      print(predicted_y.shape)
      loss = loss_function(predicted_y, y)
      train_loss += 1-loss.item()
  print(f'Test Dice Coefficient: {train_loss}%')

!pip install segmentation-models-pytorch

import torch
device = 'cuda' if torch.cuda.is_available() else 'cpu'

import segmentation_models_pytorch as smp
from torchvision.models import ResNet18_Weights
import torchvision.transforms as T
from torchvision.transforms.functional import InterpolationMode
import torch
import torchvision.models as models
import torch.nn as nn
import torch.optim as optim
from torchvision.models import ResNet18_Weights

#https://github.com/qubvel-org/segmentation_models.pytorch
model = smp.Unet(
    encoder_name="resnet18",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights="imagenet",     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=4,                      # model output channels (number of classes in your dataset)
)

transform = transforms.Compose([
    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR)
])


train_loader, val_loader, test_loader = make_dataloaders("BraTS2020_training_data/content/data/", batch_size = 120, transform = transform)

for param in model.parameters():
    param.requires_grad = True
print(device)
model = model.to(device)
trainable_params = [param for param in model.parameters() if param.requires_grad]

batch_size = 500
learning_rate = 1e-4
optimizer = optim.Adam(trainable_params, lr = learning_rate)
class_weights = torch.tensor([0, 1, 1, 1])
loss_function = DiceLoss(class_weights=class_weights)
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)
model = train_model(model, optimizer, scheduler, loss_function, 100, train_loader, val_loader, 3, "resnet18unet-fine_tune_redo")
#files.download('/content/resnet18unet-fine_tune_redo.py')

model.load_state_dict(torch.load(f"/content/drive/My Drive/DL for CV/resnet18unet-fine_tune_redo.py")) #load our best model
batch_size = 500
learning_rate = 1e-5
optimizer = optim.Adam(trainable_params, lr = learning_rate)
class_weights = torch.tensor([0, 1, 1, 1])
loss_function = DiceLoss(class_weights=class_weights)
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)
model = train_model(model, optimizer, scheduler, loss_function, 100, train_loader, val_loader, 3, "resnet18unet-fine_tune_redo-finer")
#files.download('/content/resnet18unet-fine_tune_redo.py')

model.load_state_dict(torch.load(f"/content/drive/My Drive/DL for CV/resnet18unet-fine_tune_redo-finer.py")) #load our best model
class_weights = torch.tensor([0, 1, 1, 1])
loss_function = DiceLoss(class_weights=class_weights)

model.segmentation_head = nn.Sequential(
    nn.Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # new Conv2d layer
    nn.ReLU(),  # relu activation
    nn.Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # Existing Conv2d layer
    nn.ReLU(),  # ReLU to the output
    nn.Conv2d(4, 4, kernel_size=(1, 1))  # final Conv2d to output logits for classes
)

model = model.to(device)

for param in model.parameters():
    param.requires_grad = False
for param in model.segmentation_head.parameters():
    param.requires_grad = True

trainable_params = [param for param in model.parameters() if param.requires_grad]

batch_size = 500
learning_rate = 1e-3
optimizer = optim.Adam(trainable_params, lr = learning_rate)
class_weights = torch.tensor([0, 1, 1, 1])
loss_function = DiceLoss(class_weights=class_weights)
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)
model = train_model(model, optimizer, scheduler, loss_function, 100, train_loader, val_loader, 3, "resnet18unet-finertune-finest")

learning_rate = 1e-5
optimizer = optim.Adam(trainable_params, lr = learning_rate)
model = train_model(model, optimizer, scheduler, loss_function, 100, train_loader, val_loader, 3, "resnet18unet-finertune-finest")

import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np

def test_model(model, test_loader, name, print_sample_mistakes=True):
    model.eval()
    dice = 0
    images_to_plot = 10
    plotted_images = 0
    plot_image = True


    for x, y in tqdm(test_loader, desc=f'Batching', leave=False):
        with torch.no_grad():
            x, y = x.to(device), y.to(device)
            predicted_y = model(x)
            predicted_y_softmax = F.softmax(predicted_y, dim=1)
            predicted_y_argmax = torch.argmax(predicted_y_softmax, dim=1)
            predicted_y_one_hot = F.one_hot(predicted_y_argmax, num_classes=y.size(1))
            predicted_y_one_hot = predicted_y_one_hot.permute(0, 3, 1, 2)
            loss = loss_function(predicted_y, y)
            dice += 1-loss.item()

            if (plot_image and np.random.random()>0.5):
              if print_sample_mistakes and plotted_images < images_to_plot:
                  for i in range(min(images_to_plot - plotted_images, x.size(0))):
                      plot_sample(x[i], y[i], predicted_y_one_hot[i])
                      plotted_images += 1
              if plotted_images >= images_to_plot:
                  plot_image = False
    print(f"Test Dice Coefficient {dice/len(test_loader)}.")

def plot_sample(image, true_mask, predicted_mask):
    image_np = image.cpu().numpy()
    true_mask_np = true_mask.cpu().numpy()
    predicted_mask_np = predicted_mask.cpu().numpy()

    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(np.transpose(image_np[:3], (1, 2, 0)))
    axs[0].set_title("Input Image")
    axs[0].axis("off")

    axs[1].imshow(overlay_mask(true_mask_np))
    axs[1].set_title("True Mask")
    axs[1].axis("off")

    axs[2].imshow(overlay_mask(predicted_mask_np))
    axs[2].set_title("Predicted Mask")
    axs[2].axis("off")

    plt.show()

def overlay_mask(mask):
    h, w = mask.shape[1:]
    color_map = np.array([[0, 0, 0], [0, 255, 0], [0, 0, 255], [255, 0, 0]])
    composite_mask = np.zeros((h, w, 3), dtype=np.uint8)

    for channel in range(mask.shape[0]):
        composite_mask[mask[channel] == 1] = color_map[channel % len(color_map)]

    return composite_mask

model.load_state_dict(torch.load(f"/content/resnet18unet-fine_tune_redo.py"))
test_model(model, test_loader, "resnet18unet-fine_tune_redo")

model.load_state_dict(torch.load(f"/content/drive/My Drive/DL for CV/HW_5/resnet18unet-finertune-finest.py"))
test_model(model, test_loader, "resnet18unet-finertune-finest")