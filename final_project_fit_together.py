# -*- coding: utf-8 -*-
"""final_project_fit_together.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18JXpDvDHGUWTFmSJpkuSLg2wHZgnMK5v

# Loading in the Data

Getting the dataset from kaggle, will prompt you for the kaggle.json file.
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install -q kaggle
# %cd /content
!pwd
from google.colab import files
files.upload()
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets list
from google.colab import drive
# %cd /content
!kaggle datasets download -d awsaf49/brats2020-training-data
! unzip brats2020-training-data.zip
# %cd /content
import pandas as pd

import torch
device = 'cuda' if torch.cuda.is_available() else 'cpu'





"""Survival Info Table"""

!pip install SimpleITK
import SimpleITK as sitk

def load_image(h5_file_path, channel):
    with h5py.File(h5_file_path, 'r') as file:
        image_data = file['image'][:]
    if len(image_data.shape) > 2:
        image_data = image_data[:, :, channel]
    return image_data

def n4bias_and_normalize(h5_file_path, channel):
    original_image = load_image(h5_file_path, channel)
    corrected_array = sitk.GetArrayFromImage(original_image)
    mean = np.mean(corrected_array)
    print(mean)
    std = np.std(corrected_array)
    print(std)
    normalized_array = (corrected_array - mean) / std

    mean = np.mean(normalized_array)
    print(mean)
    std = np.std(normalized_array)
    print(std)
    return original_image, corrected_array, normalized_array



h5_file_path = 'BraTS2020_training_data/content/data/volume_30_slice_50.h5'
channel = 0
i = 1
for channel in range(4):
  original, corrected, normalized = n4bias_and_normalize(h5_file_path, channel)
  plt.figure(figsize=(9, 12))

  plt.subplot(4, 3, i)
  plt.imshow(original, cmap='gray')
  plt.title('Original Image')
  plt.axis('off')
  i+=1

  plt.subplot(4, 3, i)
  plt.imshow(corrected, cmap='gray')
  plt.title('Corrected Image')
  plt.axis('off')
  i+=1

  plt.subplot(4, 3, i)
  plt.imshow(normalized, cmap='gray')
  plt.title('Normalized Image')
  plt.axis('off')
  i+=1

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import os
import random
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.colors as mcolors

image_path = '/content/BraTS2020_training_data/content/data'

images = [f for f in os.listdir(image_path) if f.endswith('.h5')]
selected_images = random.sample(images, 4)

for image in selected_images:
  with h5py.File(os.path.join(image_path, image), 'r') as file:
    image = file['image'][:]
    mask = file['mask'][:]
  plt.figure(figsize = (10,10))
  for i in range(4):
    plt.subplot(1, 7, i + 1)
    plt.imshow(image[:, :, i], cmap='gray')
    plt.title(f'Channel {i + 1}')
    plt.axis('off')

  Mask_Names = ['M0(NEC)', 'M1(ED)', 'M2(ET)']
  custom_colors = [
    mcolors.ListedColormap(['black', 'green']),
    mcolors.ListedColormap(['black', 'blue']),
    mcolors.ListedColormap(['black', 'red'])
  ]

  for i in range(4, 7):
      plt.subplot(1, 7, i + 1)
      plt.imshow(mask[:, :, i-4], cmap=custom_colors[i-4])
      plt.title(f'{Mask_Names[i-4]}')
      plt.axis('off')

  plt.show()

"""# Smriti's Code

Smriti's Code (Helper Methods and such)
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split
import numpy as np
from torchvision import transforms
import os

!pip install SimpleITK
import h5py
import SimpleITK as sitk



def n4bias_and_normalize(original_image):
    corrected_array = sitk.GetImageFromArray(original_image)
    mean = np.mean(corrected_array)
    std = np.std(corrected_array)
    normalized_array = (corrected_array - mean)
    if(std != 0):
      normalized_array = (corrected_array - mean) / std
    mean = np.mean(normalized_array)
    std = np.std(normalized_array)
    return normalized_array

def one_hot_mask(mask):
    class_mask = np.zeros((240, 240, 4), dtype=np.uint8)

    for class_idx in range(3):
        class_mask[mask[:, :, class_idx] > 0, class_idx + 1] = 1
    class_mask[mask.sum(axis=-1) == 0, 0] = 1

    return class_mask

class SegmentationDataset(Dataset):
    def __init__(self, image_path, transform=None):
        self.image_path = image_path
        self.images = [f for f in os.listdir(image_path) if f.endswith('.h5')]

        print(len(self.images))
        self.transform = transform

    def __len__(self):
      return len(self.images)
    def __getitem__(self, idx):
      try:
        with h5py.File(os.path.join(self.image_path, self.images[idx]), 'r') as file:
          image = np.array(file['image'])
          mask = np.array(file['mask'])
          image = torch.tensor(image, dtype=torch.float).permute(2, 0, 1)
          mask = one_hot_mask(mask)
          mask = torch.tensor(mask, dtype=torch.long).permute(2, 0, 1)
          image = self.transform(image)
          mask = torch.nn.functional.pad(mask, (8, 8, 8, 8), mode="constant", value=0)
          return image, mask
      except Exception as e:
        # Catch and log any error
        print(f"Error processing file {self.images[idx]}: {e}")

def make_dataloaders(image_path, batch_size, transform):
  dataset = SegmentationDataset(image_path, transform = transform)
  train_size = int(0.8 * len(dataset))
  val_size = int(0.1 * len(dataset))
  test_size = len(dataset) - train_size - val_size

  generator1 = torch.Generator().manual_seed(42)
  train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator = generator1)
  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

  return train_loader, val_loader, test_loader


class DiceLoss(nn.Module):
    def __init__(self, class_weights=None):
        super(DiceLoss, self).__init__()
        self.class_weights = class_weights

    def forward(self, predicted_mask, true_mask, smooth_coef=1.0):
        predicted_mask = torch.nn.functional.softmax(predicted_mask, dim=1) #torch.Size([batch, 4, 256, 256])
        true_mask = true_mask.float() #torch.Size([batch, 4, 256, 256])

        predicted_mask = predicted_mask.view(predicted_mask.size(0), predicted_mask.size(1), -1) #torch.Size([batch, 4, 65536])
        true_mask = true_mask.view(true_mask.size(0), true_mask.size(1), -1) #torch.Size([batch, 4, 65536])

        intersection = (predicted_mask * true_mask).sum(dim=2) #torch.Size([batch, 4])
        total = predicted_mask.sum(dim=2) + true_mask.sum(dim=2) #torch.Size([batch, 4])

        if self.class_weights is not None:
            self.class_weights = self.class_weights.to(predicted_mask.device)
            intersection = intersection * self.class_weights
            total = total * self.class_weights


        dice_score = (2 * intersection + smooth_coef) / (total + smooth_coef) #torch.Size([batch, 4])
        return 1 - dice_score.mean() #torch.Size([])


import time
import tqdm
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image
from google.colab import drive
from torch.optim.lr_scheduler import StepLR
from google.colab import files
model_path = '/content/'

def train_model(model, optimizer, scheduler, loss_function, num_epochs, train_loader, val_loader, patience, name):
  lowest_val_loss = 100000000
  patience_counter = patience
  for epoch in range(num_epochs):
    start_time = time.time()
    model.train()
    train_loss = 0
    for x, y in tqdm(train_loader, desc=f"Epoch:{epoch + 1}", leave=False):  # progress bar
      x, y = x.to(device), y.to(device)
      optimizer.zero_grad()
      predicted_y = model(x)
      y = y.float()

      loss = loss_function(predicted_y, y)  # No need for y to have requires_grad=True
      loss.backward()  # Backpropagate gradients

      optimizer.step()
      train_loss += loss.item()
    train_loss /= len(train_loader)
    model.eval()
    val_loss = 0 #checking validation loss
    for x, y in val_loader:
      x, y = x.to(device), y.to(device)
      with torch.no_grad():
        predicted_y = model(x)
        loss = loss_function(predicted_y.squeeze(), y.float())
        val_loss += loss.item()
    val_loss /= len(val_loader)

    if (val_loss<lowest_val_loss): #if our validation loss is less than the lowest one so far, save the model out
      torch.save(model.state_dict(), f"{model_path}{name}.py")
      patience_counter = patience
      lowest_val_loss = val_loss #update the lowest loss

    elif (val_loss >= lowest_val_loss):#reduce patience
      patience_counter-= 1
      if patience_counter == 0:
          print(f"Ran out of patience. Best Model Val Loss: {lowest_val_loss}")
          break;
    end_time = time.time()
    epoch_duration = end_time - start_time #timing our epoch
    print(f'Epoch{epoch+1} of num_epochs; Train Loss: {train_loss}; Val Loss: {val_loss}; Patience: {patience_counter}; Time: {epoch_duration}')
    scheduler.step()

  model.load_state_dict(torch.load(f"{model_path}{name}.py")) #load our best model
  return model


import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np

def test_model(model, test_loader, name, print_sample_mistakes=True):
    model.eval()
    dice = 0
    images_to_plot = 10
    plotted_images = 0
    plot_image = True
    mean_for_each_mask = np.array([0,0,0,0])

    for x, y in tqdm(test_loader, desc=f'Batching', leave=False):
        with torch.no_grad():
            x, y = x.to(device), y.to(device)
            predicted_y = model(x)
            predicted_y_softmax = F.softmax(predicted_y, dim=1)
            predicted_y_argmax = torch.argmax(predicted_y_softmax, dim=1)
            predicted_y_one_hot = F.one_hot(predicted_y_argmax, num_classes=y.size(1))
            predicted_y_one_hot = predicted_y_one_hot.permute(0, 3, 1, 2)
            loss, mean_each_batch = loss_function(predicted_y, y)
            mean_for_each_mask = mean_for_each_mask + mean_each_batch.cpu().numpy()
            dice += 1-loss.item()

            if (plot_image and np.random.random()>0.7):
              if print_sample_mistakes and plotted_images < images_to_plot:
                  for i in range(min(images_to_plot - plotted_images, x.size(0))):
                      plot_sample(x[i], y[i], predicted_y_one_hot[i])
                      plotted_images += 1
              if plotted_images >= images_to_plot:
                  plot_image = False
    print(f"Test Dice Coefficient {dice/len(test_loader)}.")
    print(mean_for_each_mask/len(test_loader))

def plot_sample(image, true_mask, predicted_mask):
    image_np = image.cpu().numpy()
    true_mask_np = true_mask.cpu().numpy()
    predicted_mask_np = predicted_mask.cpu().numpy()

    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(np.transpose(image_np[:3], (1, 2, 0)))
    axs[0].set_title("Input Image")
    axs[0].axis("off")

    axs[1].imshow(overlay_mask(true_mask_np))
    axs[1].set_title("True Mask")
    axs[1].axis("off")

    axs[2].imshow(overlay_mask(predicted_mask_np))
    axs[2].set_title("Predicted Mask")
    axs[2].axis("off")

    plt.show()

def overlay_mask(mask):
    h, w = mask.shape[1:]
    color_map = np.array([[0, 0, 0], [0, 255, 0], [0, 0, 255], [255, 0, 0]])
    composite_mask = np.zeros((h, w, 3), dtype=np.uint8)

    for channel in range(mask.shape[0]):
        composite_mask[mask[channel] == 1] = color_map[channel % len(color_map)]

    return composite_mask

!pip install segmentation-models-pytorch

import segmentation_models_pytorch as smp
from torchvision.models import ResNet18_Weights
import torchvision.transforms as T
from torchvision.transforms.functional import InterpolationMode
import torch
import torchvision.models as models
import torch.nn as nn
import torch.optim as optim
from torchvision.models import ResNet18_Weights

#https://github.com/qubvel-org/segmentation_models.pytorch
unet_model = smp.Unet(
    encoder_name="resnet18",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights="imagenet",     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=4,                      # model output channels (number of classes in your dataset)
)

transform = transforms.Compose([
    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR)
])

print(unet_model)

unet_model.segmentation_head = nn.Sequential(
    nn.Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # new Conv2d layer
    nn.ReLU(),  # relu activation
    nn.Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # Existing Conv2d layer
    nn.ReLU(),  # ReLU to the output
    nn.Conv2d(4, 4, kernel_size=(1, 1))  # final Conv2d to output logits for classes
)

train_loader, val_loader, test_loader = make_dataloaders("BraTS2020_training_data/content/data/", batch_size = 80, transform = transform)

for param in unet_model.parameters():
    param.requires_grad = True
unet_model = unet_model.to(device)
trainable_params = [param for param in unet_model.parameters() if param.requires_grad]

print(len(train_loader) * 80, len(val_loader)* 80, len(test_loader) * 80)

"""## Smriti's Model

Loading in UNET P.S. will take a while for it to load.
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
files.upload()

model = model.to(device)
unet_model.load_state_dict(torch.load(f"/content/resnet18unet-finertune-finest.py")) #outputs tensor of shape torch.Size([batch_size, 4, 256, 256])
class_weights = torch.tensor([0, 1, 1, 1])
loss_function = DiceLoss(class_weights=class_weights)
test_model(unet_model, test_loader, "resnet18unet-fine_tune_redo")

import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

def test_model_with_confusion_matrix_optimized(model, test_loader, name, print_sample_mistakes=True):
    model.eval()
    dice = 0
    images_to_plot = 10
    plotted_images = 0
    plot_image = True
    mean_for_each_mask = np.array([0, 0, 0, 0])

    num_classes = 4
    conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)

    for x, y in tqdm(test_loader, desc=f'Batching', leave=False):
        with torch.no_grad():
            x, y = x.to(device), y.to(device)
            predicted_y = model(x)
            predicted_y_softmax = F.softmax(predicted_y, dim=1)
            predicted_y_argmax = torch.argmax(predicted_y_softmax, dim=1)

            true_labels_argmax = torch.argmax(y, dim=1)


            batch_conf_matrix = confusion_matrix(
                true_labels_argmax.cpu().numpy().flatten(),
                predicted_y_argmax.cpu().numpy().flatten(),
                labels=np.arange(num_classes)
            )
            conf_matrix += batch_conf_matrix

            predicted_y_one_hot = F.one_hot(predicted_y_argmax, num_classes=y.size(1))
            predicted_y_one_hot = predicted_y_one_hot.permute(0, 3, 1, 2)
            loss, mean_each_batch = loss_function(predicted_y, y)
            mean_for_each_mask = mean_for_each_mask + mean_each_batch.cpu().numpy()
            dice += 1 - loss.item()

            if plot_image and np.random.random() > 0.7:
                if print_sample_mistakes and plotted_images < images_to_plot:
                    for i in range(min(images_to_plot - plotted_images, x.size(0))):
                        plot_sample(x[i], y[i], predicted_y_one_hot[i])
                        plotted_images += 1
                if plotted_images >= images_to_plot:
                    plot_image = False


    ConfusionMatrixDisplay(conf_matrix).plot(cmap='viridis', xticks_rotation='vertical')
    plt.title(f"Confusion Matrix - {name}")
    plt.show()


    print(f"Test Dice Coefficient: {dice / len(test_loader)}")
    print("Mean Metrics for Each Mask:", mean_for_each_mask / len(test_loader))

unet_model.load_state_dict(torch.load(f"/content/resnet18unet-finertune-finest.py")) #outputs tensor of shape torch.Size([batch_size, 4, 256, 256])
class_weights = torch.tensor([0, 1, 1, 1])
loss_function = DiceLoss(class_weights=class_weights)
test_model_with_confusion_matrix_optimized(unet_model, test_loader, "resnet18unet-fine_tune_redo")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

conf_matrix = np.array([
    [3.7e8, 50892, 612906, 92343],
    [39088, 635344, 5e4, 92125],
    [3e5, 67427, 1.7e6, 98263],
    [34077, 107612, 42623, 537913]
])


conf_matrix = np.log(conf_matrix)

fig, ax = plt.subplots(figsize=(8, 8))
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)
disp.plot(cmap='plasma', ax=ax, xticks_rotation='vertical', colorbar=True)

ax.set_title("Log Count Confusion Matrix - Segmentation", fontsize=14)
ax.set_xlabel("Predicted Labels", fontsize=12)
ax.set_ylabel("True Labels", fontsize=12)
plt.tight_layout()

plt.show()

"""#Divya's Code

Divya's Code
"""

import pandas as pd
import numpy as np
import h5py
import os
import random
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from PIL import Image
from torchvision.models import ResNet50_Weights
from torch.optim import lr_scheduler

data = pd.read_csv("BraTS2020_training_data/content/data/survival_info.csv")
data

meta_data = pd.read_csv("BraTS2020_training_data/content/data/meta_data.csv")
meta_data

all_ids_mask = set(range(1, meta_data['volume'].max() + 1))  # Full range of IDs
present_ids_mask = set(meta_data['volume'])
missing_ids_mask = sorted(all_ids_mask - present_ids_mask)

print(f"Missing patient IDs: {missing_ids_mask}")

# Extract volume ID from Brats20ID
data['volume'] = data['Brats20ID'].str.extract(r'(\d+)$').astype(int)
data

all_ids_survival = set(range(1, data['volume'].max() + 1))  # Full range of IDs
present_ids_survival = set(data['volume'])
missing_ids_survival = sorted(all_ids_survival - present_ids_survival)

print(f"Missing patient IDs: {missing_ids_survival}")

meta_data = meta_data[~meta_data['volume'].isin(missing_ids_survival)].reset_index(drop=True)
meta_data

# Merge the meta_data with survival information
merged_data = meta_data.merge(data[['volume', 'Age', 'Survival_days']], on='volume', how='left')
merged_data

df = merged_data.dropna()

print(f"Original meta_data size: {len(meta_data)}")
print(f"Filtered meta_data size: {len(df)}")

df = df.drop(columns=['target', 'volume', 'slice'])
df

import re

def clean_survival_days(value):
  if isinstance(value, str) and 'ALIVE' in value:
    return float(re.search(r'\d+', value).group())  # Extract the number directly
  return float(value)

df['Survival_days'] = df['Survival_days'].apply(clean_survival_days)

print(df['Survival_days'].unique())

print(df['Age'].describe())
print(df['Survival_days'].describe())

df['Survival_bins'] = pd.qcut(df['Survival_days'], q=3, labels=[0, 1, 2])
label_map = {0: 'Short', 1: 'Medium', 2: 'Long'}
df

print(df['Survival_bins'].value_counts())
print(df.groupby('Survival_bins')['Survival_days'].agg(['min', 'max']))

def train_model(model, train_loader, val_loader, criterion, scheduler, optimizer, patience, num_epochs):
  best_loss = float('inf')
  no_improvement_epochs = 0
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

  for epoch in range(num_epochs):
    model.train()
    train_loss = 0
    correct = 0
    for mask, age, labels in train_loader:
      mask, age, labels = mask.to(device), age.to(device), labels.to(device)

      outputs = model(mask, age)  # Forward pass
      loss = criterion(outputs, labels.long()) # Compute loss

      optimizer.zero_grad()  # Reset gradients
      loss.backward()  # Backward pass
      optimizer.step()  # Update weights

      train_loss += loss.item()

      # For classification
      _, preds = torch.max(outputs, 1)
      correct += torch.sum(preds == labels).item()

    train_loss /= len(train_loader)
    train_acc = correct / len(train_loader.dataset)

    print(f"Epoch {epoch+1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.4f}  Train Accuracy: {train_acc:.4f}")

    val_loss, val_acc = validate_model(model, val_loader, criterion)
    print(f"Validation Loss: {val_loss:.4f} Validation Accuracy: {val_acc:.4f}\n")

    if val_loss < best_loss:
      best_loss = val_loss
      torch.save(model.state_dict(), f'best_model_resnet50.pth')
    else:
      no_improvement_epochs += 1
      if no_improvement_epochs >= patience:
        print("Early stopping due to no improvement in validation loss.")
        break

    scheduler.step()

def validate_model(model, val_loader, criterion):
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  model.eval()
  model.to(device)
  val_loss = 0
  correct = 0

  with torch.no_grad():
    for mask, age, labels in val_loader:
      mask, age, labels = mask.to(device), age.to(device), labels.to(device)
      outputs = model(mask, age) # Forward pass
      loss = criterion(outputs, labels.long())  # Compute loss

      val_loss += loss.item()     # Accumulate loss

      # For classification
      _, preds = torch.max(outputs, 1)
      correct += torch.sum(preds == labels).item()

  val_loss /= len(val_loader) # Calculate average validation loss
  val_acc = correct / len(val_loader.dataset)
  return val_loss, val_acc

def test_model(model, test_loader, criterion):
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  model.eval()
  model.to(device)
  test_loss = 0
  correct = 0

  correct_each_bin = torch.zeros(3, dtype=torch.int32, device=device)  # 3 bins: 0, 1, 2
  total_each_bin = torch.zeros(3, dtype=torch.int32, device=device)

  with torch.no_grad():
    for images, age, labels in test_loader:
      images, age, labels = images.to(device), age.to(device), labels.to(device)
      outputs = model(images, age)  # Forward pass
      loss = criterion(outputs, labels.long())  # Compute loss

      test_loss += loss.item()  # Accumulate loss
      _, preds = torch.max(outputs, 1)

      correct += torch.sum(preds == labels).item()

      # Update bin-specific counts
      for bin_id in range(3):  # Assuming 3 bins
        correct_each_bin[bin_id] += torch.sum((preds == labels) & (labels == bin_id))
        total_each_bin[bin_id] += torch.sum(labels == bin_id)

  test_loss /= len(test_loader)  # Average test loss
  test_acc = correct / len(test_loader.dataset)
  print(f"Test Loss: {test_loss:.4f}")
  print(f"Test Accuracy: {test_acc:.4f}")

  # Calculate and print accuracy for each bin
  bin_accuracies = correct_each_bin.float() / total_each_bin.float()

  return test_loss, test_acc, bin_accuracies

import torch
from torch.utils.data import Dataset
from PIL import Image
import h5py
import pandas as pd

class MaskDataset(Dataset):
  def __init__(self, dataframe, data_dir, preprocess=None):
    self.dataframe = dataframe
    self.data_dir = data_dir
    self.preprocess = preprocess
    self.min_age = self.dataframe['Age'].min()
    self.max_age = self.dataframe['Age'].max()

  def __len__(self):
    return len(self.dataframe)

  def __getitem__(self, idx):
    # Get the row corresponding to the idx
    row = self.dataframe.iloc[idx]
    slice_path = row['slice_path']

    # Load the mask from the H5 file
    with h5py.File(f'{self.data_dir}/{slice_path}', 'r') as file:
      mask = file['mask'][:]

    mask_combined = np.stack([mask[:, :, 0], mask[:, :, 1], mask[:, :, 2]], axis=-1)
    mask_combined = Image.fromarray((mask_combined * 255).astype(np.uint8))

    if self.preprocess:
      mask_tensor = self.preprocess(mask_combined)

    label = row['Survival_bins']
    age = row['Age']
    scaled_age = (age - self.min_age) / (self.max_age - self.min_age)

    # Convert to tensor
    label_tensor = torch.tensor(label, dtype=torch.float32)
    age_tensor = torch.tensor(scaled_age, dtype=torch.float32)

    return mask_tensor, age_tensor, label_tensor

from torch.utils.data import DataLoader

# Split the data into train, validation, and test sets
train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Survival_bins'], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Survival_bins'], random_state=42)
print(f"Training data size: {train_df.shape}")
print(f"Validation data size: {val_df.shape}")
print(f"Test data size: {test_df.shape}")

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import seaborn as sns

def batch_process_pca(dataframe, data_dir, batch_size):
  pca_results = []
  scaler = StandardScaler()
  pca = PCA(n_components=2)

  for start in range(0, len(dataframe), batch_size):
    end = start + batch_size
    batch = dataframe.iloc[start:end]

    masks_batch = np.array([
      h5py.File(f"{data_dir}/{row['slice_path']}", 'r')['mask'][:].flatten()
      for _, row in batch.iterrows()
    ])

    masks_scaled = scaler.fit_transform(masks_batch)
    masks_pca = pca.fit_transform(masks_scaled)
    pca_results.append(masks_pca)

  return np.vstack(pca_results)


data_dir = 'BraTS2020_training_data'
masks_pca = batch_process_pca(train_df, data_dir, batch_size=500)

pca_df = pd.DataFrame(masks_pca, columns=['PCA1', 'PCA2'])
pca_df['Survival_bins'] = df['Survival_bins']

plt.figure(figsize=(10, 6))
sns.scatterplot(data=pca_df, x='PCA1', y='PCA2', hue='Survival_bins', palette='viridis', s=50)
plt.title('PCA of Mask Pixel Values Colored by Survival Bins')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.legend(title='Survival Bins')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(
  data=train_df,
  x='Age',
  y='Survival_days',
  hue='Survival_bins',
  palette='viridis',
  alpha=0.7
)

plt.title('Scatter Plot of Age vs Survival Days')
plt.xlabel('Age')
plt.ylabel('Survival Days')
plt.legend(title='Survival Bins', loc='best')
plt.show()

mask_transforms = transforms.Compose([
    transforms.Resize(232),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize for ResNet50
])

test_dataset = MaskDataset(test_df, 'BraTS2020_training_data', mask_transforms)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)

class CustomResNet50Model(nn.Module):
  def __init__(self, num_classes):
    super(CustomResNet50Model, self).__init__()
    self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)

    self.resnet.fc = nn.Sequential(
        nn.Linear(self.resnet.fc.in_features, 128),
        nn.ReLU(),
        nn.Dropout(0.3)
    )

    # Age processing layer
    self.age_layer = nn.Sequential(
        nn.Linear(1, 10),
        nn.ReLU(),
        nn.Linear(10, 10)
    )

    # Final combined layer to merge image and age features
    self.combined_layer = nn.Sequential(
        nn.Linear(128 + 10, 256),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(256, 128),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(128, num_classes)
    )

  def forward(self, x_image, x_age):
    x_age = x_age.unsqueeze(1)          # shape: [batch_size, 1]
    age_features = self.age_layer(x_age)
    image_features = self.resnet(x_image)

    # Concatenate the image and age features
    combined_features = torch.cat((image_features, age_features), dim=1)
    output = self.combined_layer(combined_features)

    return output

"""# Divya's Model"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
files.upload()

resnet_model = CustomResNet50Model(num_classes=3)
resnet_model.to(device)
resnet_model.load_state_dict(torch.load('best_model_resnet50.pth', weights_only=True))
criterion = nn.CrossEntropyLoss()
test_loss, test_acc = test_model(resnet_model, test_loader, criterion)

"""#Fitted together"""

class FinalDataset(Dataset):
    def __init__(self, dataframe, image_path, transform=None):
        self.image_path = image_path
        self.dataframe = dataframe
        self.transform = transform
        self.min_age = self.dataframe['Age'].min()
        self.max_age = self.dataframe['Age'].max()

    def __len__(self):
      return len(self.dataframe)

    def __getitem__(self, idx):
      try:
        row = self.dataframe.iloc[idx]
        slice_path = row['slice_path']
        print(idx)
        print(slice_path)

        with h5py.File(f'{self.image_path}/{slice_path}', 'r') as file:
          image = np.array(file['image'])
          image = torch.tensor(image, dtype=torch.float).permute(2, 0, 1)
          image = self.transform(image)

          label = row['Survival_bins']
          age = row['Age']
          scaled_age = (age - self.min_age) / (self.max_age - self.min_age)

          # Convert to tensor
          label_tensor = torch.tensor(label, dtype=torch.float32)
          age_tensor = torch.tensor(scaled_age, dtype=torch.float32)
          return image, age_tensor, label_tensor, idx

      except Exception as e:
        # Catch and log any error
        print(f"Error processing file {self.dataframe.iloc[idx]}: {e}")

def test_model_final(unet, resnet, loss_function, test_loader_segmentation, mask_transform):
    unet.eval()
    resnet.eval()
    test_loss = 0
    correct = 0
    correct_each_bin = np.array([0,0,0])
    total_each_bin = np.array([0,0,0])

    for images, age, labels in test_loader_segmentation:
      with torch.no_grad():
        images, age, labels = images.to(device), age.to(device), labels.to(device) #images, age tensor, label tensor

        predicted_y = unet(images)                # shape: batch, 4, 256, 256
        predicted_y_softmax = F.softmax(predicted_y, dim=1)
        predicted_y_argmax = torch.argmax(predicted_y_softmax, dim=1) #see what the dimension [0, 1, 2, 3, 0  ,....]
        #print(f"Mask argmax shape: {predicted_y_argmax.shape}")   # shape: batch, 256, 256
        predicted_y_one_hot = F.one_hot(predicted_y_argmax, num_classes=4)
        predicted_y_one_hot = predicted_y_one_hot.permute(0, 3, 1, 2) #batch, 4, 256, 256

        # (0th channel background)/preprocess
        mask = predicted_y_one_hot[:, 1:, :, :]

        # apply mask transformations for resnet
        transformed_masks = []
        for i in range(mask.shape[0]):
          mask_np = mask[i].permute(1, 2, 0).cpu().numpy()  # shape: [256, 256, 3]
          mask_img = Image.fromarray((mask_np * 255).astype(np.uint8))

          mask_transformed = mask_transform(mask_img)  # shape: [3, 224, 224]
          transformed_masks.append(mask_transformed)

        mask_batch = torch.stack(transformed_masks).to(device)  # shape: [128, 3, 224, 224]
        outputs = resnet(mask_batch, age)  # Forward pass
        loss = loss_function(outputs, labels.long())  # Compute loss

        test_loss += loss.item()     # Accumulate loss
        _, preds = torch.max(outputs, 1)
        label_correct = np.array([torch.sum(torch.logical_and(preds == i, labels == i)).item() for i in range(3)])
        num_label = np.array([torch.sum((labels == i)).item() for i in range (3)])
        correct_each_bin = correct_each_bin + label_correct
        total_each_bin = total_each_bin + num_label
        correct += torch.sum(preds == labels).item()

    test_loss /= len(test_loader_segmentation)  # Calculate average test loss
    test_acc = correct / len(test_loader_segmentation.dataset)
    print(f"Test Loss: {test_loss:.4f}")
    print(f"Test Accuracy: {test_acc:.4f}")

    return test_loss, test_acc, correct_each_bin/total_each_bin

    # print(f"Test Loss {dice/len(test_loader_segmentation)}.")

import pandas as pd
import torch.nn.functional as F

def test_model_final(unet, resnet, loss_function, test_loader_segmentation, mask_transform):
    unet.eval()
    resnet.eval()
    test_loss = 0
    correct = 0
    correct_each_bin = np.array([0, 0, 0])
    total_each_bin = np.array([0, 0, 0])
    rows = []


    for images, age, labels, idx in test_loader_segmentation:
        with torch.no_grad():
            print(age, labels, idx)
            images, age, labels = images.to(device), age.to(device), labels.to(device)  # images, age tensor, label tensor

            predicted_y = unet(images)  # shape: batch, 4, 256, 256
            predicted_y_softmax = F.softmax(predicted_y, dim=1)
            predicted_y_argmax = torch.argmax(predicted_y_softmax, dim=1)  # see what the dimension [0, 1, 2, 3, 0 ,....]
            predicted_y_one_hot = F.one_hot(predicted_y_argmax, num_classes=4)
            predicted_y_one_hot = predicted_y_one_hot.permute(0, 3, 1, 2)  # batch, 4, 256, 256

            # (0th channel background)/preprocess
            mask = predicted_y_one_hot[:, 1:, :, :]  # Remove background channel (only 1, 2, 3 classes)

            #calculating mask percentages
            batch_size, num_classes, height, width = mask.shape
            class_sums = mask.view(batch_size, num_classes, -1).sum(dim=-1)  # sum pixels per class
            percentages = class_sums / (height * width)  # shape: [batch_size, num_classes]


            # apply mask transformations for ResNet
            transformed_masks = []
            for i in range(mask.shape[0]):
                mask_np = mask[i].permute(1, 2, 0).cpu().numpy()  # shape: [256, 256, 3]
                mask_img = Image.fromarray((mask_np * 255).astype(np.uint8))

                mask_transformed = mask_transform(mask_img)  # shape: [3, 224, 224]
                transformed_masks.append(mask_transformed)

            mask_batch = torch.stack(transformed_masks).to(device)  # shape: [batch_size, 3, 224, 224]
            outputs = resnet(mask_batch, age)  # Forward pass
            loss = loss_function(outputs, labels.long())  # Compute loss

            test_loss += loss.item()  # Accumulate loss
            _, preds = torch.max(outputs, 1)
            label_correct = np.array([torch.sum(torch.logical_and(preds == i, labels == i)).item() for i in range(3)])
            num_label = np.array([torch.sum((labels == i)).item() for i in range(3)])
            correct_each_bin = correct_each_bin + label_correct
            total_each_bin = total_each_bin + num_label
            correct += torch.sum(preds == labels).item()

            for i in range(batch_size):
                row = {
                    "m0_percentage": percentages[i, 0].item(),
                    "m1_percentage": percentages[i, 1].item(),
                    "m2_percentage": percentages[i, 2].item(),
                    "true_bin": labels[i].item(),
                    "predicted_bin": preds[i].item(),
                    "age": age[i].item(),
                    "idx": idx[i].item()
                }
                rows.append(row)

    test_loss /= len(test_loader_segmentation)  # Calculate average test loss
    test_acc = correct / len(test_loader_segmentation.dataset)
    print(f"Test Loss: {test_loss:.4f}")
    print(f"Test Accuracy: {test_acc:.4f}")

    results_df = pd.DataFrame(rows, columns=["m0_percentage", "m1_percentage", "m2_percentage", "true_bin", "predicted_bin", "age", "idx"])


    # returning the results DataFrame along with the loss and accuracy
    return test_loss, test_acc, correct_each_bin / total_each_bin, results_df

df

from torch.utils.data import DataLoader

# Split the data into train, validation, and test sets
train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Survival_bins'], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Survival_bins'], random_state=42)
print(f"Training data size: {train_df.shape}")
print(f"Validation data size: {val_df.shape}")
print(f"Test data size: {test_df.shape}")

mask_transform = transforms.Compose([
    transforms.Resize(232),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

image_transform = transforms.Compose([
    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR)
])

test_dataset_final = FinalDataset(test_df, 'BraTS2020_training_data', image_transform)
test_loader_final = DataLoader(test_dataset_final, batch_size=30, shuffle=False, num_workers=2)

unet_model.to(device)
resnet_model.to(device)

unet_model.load_state_dict(torch.load(f"resnet18unet-finertune-finest.py"))
resnet_model.load_state_dict(torch.load('best_model_resnet50.pth', weights_only=True))

criterion = nn.CrossEntropyLoss()

test_loss, test_acc, correct_each_bin, results_df = test_model_final(unet_model, resnet_model, criterion, test_loader_final, mask_transform)

print(test_loss)
print(test_acc)
print(correct_each_bin)

print(results_df)
# create a new column slice_path by looking up each row based on the idx column
# then add the 'slice_path' column by looking up the value in some_dataframe based on idx
results_df['slice_path'] = results_df['idx'].apply(lambda idx: test_df.iloc[idx]['slice_path'])

# Display the updated DataFrame
print(df.head())
results_df['volume_id'] = results_df['slice_path'].apply(lambda x: x.split('/')[-1].split('_slice')[0])

results_df.to_csv("mask_percentages_vs_bins.csv", index=False)

print(results_df.head())

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

results_df = pd.read_csv("mask_percentages_vs_bins.csv")
selected_columns = ["m0_percentage", "m1_percentage", "m2_percentage"]
results_df = results_df[results_df[selected_columns].sum(axis=1) > 0]

majority_vote = results_df.groupby("volume_id")["predicted_bin"].agg(lambda x: x.value_counts().idxmax())

results_df["majority_pred_bin"] = results_df["volume_id"].map(majority_vote)

#print(results_df)


selected_columns = ["m0_percentage", "m1_percentage", "m2_percentage"]

grouped = results_df.groupby("predicted_bin")[selected_columns].mean()

plt.figure(figsize=(8, 6))
sns.heatmap(grouped, annot=True, cmap="coolwarm", fmt=".2f",
            xticklabels=["NEC", "ED", "ET"],
            yticklabels=[f"Bin {i}" for i in grouped.index])
plt.title("Heatmap of Mask Percentages vs Bin Assignment")
plt.xlabel("Mask Classes")
plt.ylabel("Survival Bins")
plt.show()

match_predicted_bin = (results_df["true_bin"] == results_df["predicted_bin"]).mean() * 100
match_majority_bin = (results_df["true_bin"] == results_df["majority_pred_bin"]).mean() * 100

print(f"Percentage where true_bin matches predicted_bin: {match_predicted_bin:.2f}%")
print(f"Percentage where true_bin matches majority_pred_bin: {match_majority_bin:.2f}%\n")

bin_results = results_df.groupby("true_bin").apply(
    lambda group: pd.Series({
        "match_predicted_bin": (group["true_bin"] == group["predicted_bin"]).mean() * 100,
        "match_majority_bin": (group["true_bin"] == group["majority_pred_bin"]).mean() * 100
    })
)

print(bin_results)

