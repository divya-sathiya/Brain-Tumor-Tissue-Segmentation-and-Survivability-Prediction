# -*- coding: utf-8 -*-
"""FinalModel-ResNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HtHWPx-7WWrOkJRewVRlsF4JRCEV3_w8
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
# %cd /content

!kaggle datasets download awsaf49/brats2020-training-data

!unzip brats2020-training-data.zip

import pandas as pd
import numpy as np
import h5py
import os
import random
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from PIL import Image
from torchvision.models import ResNet50_Weights
from torchvision.transforms import functional as F
from torch.optim import lr_scheduler

directory = "BraTS2020_training_data/content/data"
csv = [f for f in os.listdir(directory) if f.endswith('.csv')]
print(f"Found {len(csv)} csv files")
print(csv)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
data = pd.read_csv("BraTS2020_training_data/content/data/survival_info.csv")
data

meta_data = pd.read_csv("BraTS2020_training_data/content/data/meta_data.csv")
meta_data

all_ids_mask = set(range(1, meta_data['volume'].max() + 1))  # Full range of IDs
present_ids_mask = set(meta_data['volume'])
missing_ids_mask = sorted(all_ids_mask - present_ids_mask)

print(f"Missing patient IDs: {missing_ids_mask}")

# Extract volume ID from Brats20ID
data['volume'] = data['Brats20ID'].str.extract(r'(\d+)$').astype(int)
data

all_ids_survival = set(range(1, data['volume'].max() + 1))  # Full range of IDs
present_ids_survival = set(data['volume'])
missing_ids_survival = sorted(all_ids_survival - present_ids_survival)

print(f"Missing patient IDs: {missing_ids_survival}")

meta_data = meta_data[~meta_data['volume'].isin(missing_ids_survival)].reset_index(drop=True)
meta_data

# Merge the meta_data with survival information
merged_data = meta_data.merge(data[['volume', 'Age', 'Survival_days']], on='volume', how='left')
merged_data

directory = "BraTS2020_training_data/content/data"

h5_files = [f for f in os.listdir(directory) if f.endswith('.h5')]
print(f"Found {len(h5_files)} .h5 files")
if h5_files:
    selected_file = random.choice(h5_files)
    file_path = os.path.join(directory, selected_file)
    with h5py.File(file_path, 'r') as file:
        print("\nKeys for each file:", list(file.keys()))
        for key in file.keys():
            print(f"\nData type of {key}:", type(file[key][()]))
            print(f"Shape of {key}:", file[key].shape)
            print(f"Array dtype: {file[key].dtype}")
            print(f"Array max val: {np.max(file[key])}")
            print(f"Array min val: {np.min(file[key])}")
else:
    print("No .h5 files found in the directory.")

with h5py.File('BraTS2020_training_data/content/data/volume_100_slice_48.h5', 'r') as file:
  image = file['image'][:]
  mask = file['mask'][:]

plt.figure(figsize = (10,10))

for i in range(4):
  plt.subplot(2, 4, i + 1)
  plt.imshow(image[:, :, i], cmap='gray')
  plt.title(f'Channel {i + 1}')
  plt.axis('off')

for i in range(3):
  plt.subplot(2, 4, i + 5)
  plt.imshow(mask[:, :, i], cmap='gray')
  plt.title(f'Mask Channel {i + 1}')
  plt.axis('off')

with h5py.File('BraTS2020_training_data/content/data/volume_100_slice_48.h5', 'r') as file:
  image = file['image'][:]
  mask = file['mask'][:]

image_combined = np.stack([image[:, :, 0], image[:, :, 1], image[:, :, 2]], axis=-1)  # First 3 channels as RGB
image_combined = np.clip(image_combined / np.max(image_combined), 0, 1)

mask_combined = np.stack([mask[:, :, 0], mask[:, :, 1], mask[:, :, 2]], axis=-1)
mask_combined = Image.fromarray((mask_combined * 255).astype(np.uint8))

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.imshow(image_combined)
plt.title('Image')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(mask_combined)
plt.title('Mask')
plt.axis('off')

plt.tight_layout()
plt.show()

df = merged_data.dropna()

print(f"Original meta_data size: {len(meta_data)}")
print(f"Filtered meta_data size: {len(df)}")

df = df.drop(columns=['target', 'volume', 'slice'])
df

import re

def clean_survival_days(value):
  if isinstance(value, str) and 'ALIVE' in value:
    return float(re.search(r'\d+', value).group())  # Extract the number directly
  return float(value)

# Apply the function to the 'Survival_days' column
df['Survival_days'] = df['Survival_days'].apply(clean_survival_days)

# Check the cleaned values
print(df['Survival_days'].unique())

print(df['Age'].describe())

print(df['Survival_days'].describe())

# df['Survival_bins'] = pd.qcut(df['Survival_days'], q=4, labels=[0, 1, 2, 3])
# label_map = {'Short': 0, 'Medium': 1, 'Long': 2, 'Very long': 3}
# df

df['Survival_bins'] = pd.qcut(df['Survival_days'], q=3, labels=[0, 1, 2])
label_map = {0: 'Short', 1: 'Medium', 2: 'Long'}
df

print(df['Survival_bins'].value_counts())
print(df.groupby('Survival_bins')['Survival_days'].agg(['min', 'max']))

def train_model(model, train_loader, val_loader, criterion, scheduler, optimizer, patience, num_epochs):
  best_loss = float('inf')
  no_improvement_epochs = 0
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

  for epoch in range(num_epochs):
    model.train()
    train_loss = 0
    correct = 0
    for images, age, labels in train_loader:
      images, age, labels = images.to(device), age.to(device), labels.to(device)

      outputs = model(images, age)  # Forward pass
      loss = criterion(outputs, labels.long()) # Compute loss

      optimizer.zero_grad()  # Reset gradients
      loss.backward()  # Backward pass
      optimizer.step()  # Update weights

      train_loss += loss.item()

      # For classification
      _, preds = torch.max(outputs, 1)
      correct += torch.sum(preds == labels).item()

    train_loss /= len(train_loader)
    train_acc = correct / len(train_loader.dataset)

    print(f"Epoch {epoch+1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.4f}  Train Accuracy: {train_acc:.4f}")

    val_loss, val_acc = validate_model(model, val_loader, criterion)
    print(f"Validation Loss: {val_loss:.4f} Validation Accuracy: {val_acc:.4f}\n")

    if val_loss < best_loss:
      best_loss = val_loss
      torch.save(model.state_dict(), f'best_model_resnet50.pth')
    else:
      no_improvement_epochs += 1
      if no_improvement_epochs >= patience:
        print("Early stopping due to no improvement in validation loss.")
        break

    scheduler.step()

def validate_model(model, val_loader, criterion):
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  model.eval()
  model.to(device)
  val_loss = 0
  correct = 0

  with torch.no_grad():
    for images, age, labels in val_loader:
      images, age, labels = images.to(device), age.to(device), labels.to(device)
      outputs = model(images, age) # Forward pass
      loss = criterion(outputs, labels.long())  # Compute loss

      val_loss += loss.item()     # Accumulate loss

      # For classification
      _, preds = torch.max(outputs, 1)
      correct += torch.sum(preds == labels).item()

  val_loss /= len(val_loader) # Calculate average validation loss
  val_acc = correct / len(val_loader.dataset)
  return val_loss, val_acc

def test_model(model, test_loader, criterion):
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  model.eval()
  model.to(device)
  test_loss = 0
  correct = 0
  all_labels = []
  all_preds = []

  correct_each_bin = torch.zeros(3, dtype=torch.int32, device=device)  # 3 bins: 0, 1, 2
  total_each_bin = torch.zeros(3, dtype=torch.int32, device=device)

  with torch.no_grad():
    for images, age, labels in test_loader:
      images, age, labels = images.to(device), age.to(device), labels.to(device)
      outputs = model(images, age)  # Forward pass
      loss = criterion(outputs, labels.long())  # Compute loss

      test_loss += loss.item()  # Accumulate loss
      _, preds = torch.max(outputs, 1)

      correct += torch.sum(preds == labels).item()
      all_labels.extend(labels.cpu().numpy())
      all_preds.extend(preds.cpu().numpy())

      # Update bin-specific counts
      for bin_id in range(3):  # Assuming 3 bins
        correct_each_bin[bin_id] += torch.sum((preds == labels) & (labels == bin_id))
        total_each_bin[bin_id] += torch.sum(labels == bin_id)

  test_loss /= len(test_loader)  # Average test loss
  test_acc = correct / len(test_loader.dataset)
  print(f"Test Loss: {test_loss:.4f}")
  print(f"Test Accuracy: {test_acc:.4f}")

  # Calculate and print accuracy for each bin
  bin_accuracies = correct_each_bin.float() / total_each_bin.float()

  return test_loss, test_acc, bin_accuracies, all_labels, all_preds

import torch
from torch.utils.data import Dataset
from PIL import Image
import h5py
import pandas as pd

class MaskDataset(Dataset):
  def __init__(self, dataframe, data_dir, preprocess=None):
    self.dataframe = dataframe
    self.data_dir = data_dir
    self.preprocess = preprocess
    self.min_age = self.dataframe['Age'].min()
    self.max_age = self.dataframe['Age'].max()

  def __len__(self):
    return len(self.dataframe)

  def __getitem__(self, idx):
    # Get the row corresponding to the idx
    row = self.dataframe.iloc[idx]
    slice_path = row['slice_path']

    # Load the mask from the H5 file
    with h5py.File(f'{self.data_dir}/{slice_path}', 'r') as file:
      mask = file['mask'][:]

    mask_combined = np.stack([mask[:, :, 0], mask[:, :, 1], mask[:, :, 2]], axis=-1)
    mask_combined = Image.fromarray((mask_combined * 255).astype(np.uint8))

    if self.preprocess:
      mask_tensor = self.preprocess(mask_combined)

    label = row['Survival_bins']
    age = row['Age']
    scaled_age = (age - self.min_age) / (self.max_age - self.min_age)

    # Convert to tensor
    label_tensor = torch.tensor(label, dtype=torch.float32)
    age_tensor = torch.tensor(scaled_age, dtype=torch.float32)

    return mask_tensor, age_tensor, label_tensor

from torch.utils.data import DataLoader

# Split the data into train, validation, and test sets
train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Survival_bins'], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Survival_bins'], random_state=42)
print(f"Training data size: {train_df.shape}")
print(f"Validation data size: {val_df.shape}")
print(f"Test data size: {test_df.shape}")

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import seaborn as sns

def batch_process_pca(dataframe, data_dir, batch_size):
  pca_results = []
  scaler = StandardScaler()
  pca = PCA(n_components=2)

  for start in range(0, len(dataframe), batch_size):
    end = start + batch_size
    batch = dataframe.iloc[start:end]

    masks_batch = np.array([
      h5py.File(f"{data_dir}/{row['slice_path']}", 'r')['mask'][:].flatten()
      for _, row in batch.iterrows()
    ])

    masks_scaled = scaler.fit_transform(masks_batch)
    masks_pca = pca.fit_transform(masks_scaled)
    pca_results.append(masks_pca)

  return np.vstack(pca_results)


data_dir = 'BraTS2020_training_data'
masks_pca = batch_process_pca(train_df, data_dir, batch_size=500)

pca_df = pd.DataFrame(masks_pca, columns=['PCA1', 'PCA2'])
pca_df['Survival_bins'] = df['Survival_bins']

plt.figure(figsize=(10, 6))
sns.scatterplot(data=pca_df, x='PCA1', y='PCA2', hue='Survival_bins', palette='viridis', s=50)
plt.title('PCA of Mask Pixel Values Colored by Survival Bins')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.legend(title='Survival Bins')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(
  data=train_df,
  x='Age',
  y='Survival_days',
  hue='Survival_bins',
  palette='viridis',
  alpha=0.7
)

plt.title('Scatter Plot of Age vs Survival Days')
plt.xlabel('Age')
plt.ylabel('Survival Days')
plt.legend(title='Survival Bins', loc='best')
plt.show()

"""### Training"""

mask_transforms = transforms.Compose([
    transforms.Resize(232),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize for ResNet50
])

train_dataset = MaskDataset(train_df, 'BraTS2020_training_data', mask_transforms)
val_dataset = MaskDataset(val_df, 'BraTS2020_training_data', mask_transforms)
test_dataset = MaskDataset(test_df, 'BraTS2020_training_data', mask_transforms)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)

class CustomResNet50Model(nn.Module):
  def __init__(self, num_classes):
    super(CustomResNet50Model, self).__init__()
    self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)

    self.resnet.fc = nn.Sequential(
        nn.Linear(self.resnet.fc.in_features, 128),
        nn.ReLU(),
        nn.Dropout(0.3)
    )

    # Age processing layer
    self.age_layer = nn.Sequential(
        nn.Linear(1, 10),
        nn.ReLU(),
        nn.Linear(10, 10)
    )

    # Final combined layer to merge image and age features
    self.combined_layer = nn.Sequential(
        nn.Linear(128 + 10, 256),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(256, 128),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(128, num_classes)
    )

  def forward(self, x_mask, x_age):
    x_age = x_age.unsqueeze(1)
    #print(f"Shape of x_age: {x_age.shape}")
    age_features = self.age_layer(x_age)
    image_features = self.resnet(x_mask)

    # Concatenate the image and age features
    combined_features = torch.cat((image_features, age_features), dim=1)
    output = self.combined_layer(combined_features)

    return output

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
custom_model = CustomResNet50Model(num_classes=3)
custom_model.to(device)

!pip install torchviz

from torchviz import make_dot

x_mask = torch.randn(1, 3, 224, 224).to(device)  # Example input for the mask
x_age = torch.randn(1, 1).to(device)  # Example input for the age

resnet_output = custom_model.resnet(x_mask)
age_output = custom_model.age_layer(x_age)

# Visualize each output
dot_resnet = make_dot(resnet_output, params=dict(custom_model.resnet.named_parameters()))
dot_age = make_dot(age_output, params=dict(custom_model.age_layer.named_parameters()))

# Render each diagram separately
dot_resnet.render('resnet_architecture', format='png', cleanup=True)
dot_age.render('age_layer_architecture', format='png', cleanup=True)

ResNet50_Weights.IMAGENET1K_V2.transforms

num_epochs = 50
patience = 8
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(custom_model.parameters(), lr=0.0001)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
train_model(custom_model, train_loader, val_loader, criterion, scheduler, optimizer, patience, num_epochs)

criterion = nn.CrossEntropyLoss()
custom_model.load_state_dict(torch.load('best_model_resnet50.pth', weights_only=True))
test_loss, test_acc, bin_acc, y_true, y_pred = test_model(custom_model, test_loader, criterion)
print("Bin Accuracies")
for bin_id, acc in enumerate(bin_acc):
    print(f"{bin_id}: {acc:.4f}")

from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

conf_matrix = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['0', '1', '2'],
            yticklabels=['0', '1', '2'])

plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import label_binarize
import torch

# Binarize the labels for ROC/AUC calculation
y_true_bin = label_binarize(y_true, classes=[0, 1, 2])
y_pred_bin = label_binarize(y_pred, classes=[0, 1, 2])

# Calculate ROC curve and AUC for each bin
fpr = {}
tpr = {}
roc_auc = {}

for i in range(3):  # number of bins
  fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])
  roc_auc[i] = auc(fpr[i], tpr[i])

# Plot ROC curves for each bin
plt.figure(figsize=(10, 7))
colors = ['blue', 'green', 'red']
for i in range(3):
  plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'{i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Class')
plt.legend(loc='lower right')
plt.show()

